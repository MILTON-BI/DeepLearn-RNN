# 卷积神经网络CNN
    - 应用领域：
        - 自然语言处理
        - 围棋人际对弈
        - 机器视觉：最广泛、最成功的领域，如图像分类、（图像中）物体检测、空间分割


## 全连接神经网络的局限性
    - 当图像分辨率提高、通道数增加、隐藏层节点增加，会导致参数数量急剧增加，计算速度减慢，以及容易产生过拟合问题
        - 如600*600的rgb图像，三个隐藏层节点数量300、200、100，则参数个数=600*600*300+300*200+200*100，约1.08亿
        - 因此需要合理的结构来减少参数数量

# CNN的结构
    - CNN是一个多层神经网络，每层由多个二维平面组成，每个平面由多个独立神经元组成
        - 输入层：每个像素代表一个特征节点输入网络
        - 卷积层：卷积运算主要目的是使原信号特征增强，并降低噪音（通过卷积核的参数设置）
        - 降采样层（池化层）：降低神经网络训练参数及模型的过拟合程度（降采样就是把分辨率高的图像转化成分别率低的图像）
        - 全连接层：对生成的特征进行加权
        - softmax层：获得当前样例属于不同类别的概率

    - 与全连接神经网络的异同：
        - 两种网络在架构上相似
            - 输入层、全连接层和softmax层是一样的；
            - 全连接神经网络的激活函数、参数的优化过程等，都可以用于卷积神经网络
        - 两者唯一的区别在于在CNN中，相邻两层的连接方式的不同，体现在网络结构上就是卷积层和降采样层

# 卷积（卷积层操作）
    - 卷积核在图像的二维输入数据上进行“滑动”，对当前输入部分的元素（与权值矩阵）进行矩阵乘法，然后将结果汇总为单个输出像素值，重复这个过程直到遍历整张图像，这个过程就叫卷积；
        - 这个权值矩阵就是卷积核
            - 每个卷积核都是一种特征的提取方式，将图像中符合条件的部分筛选出来。不同的卷积核提取的突出特征是不同的。
            - 对图像用卷积核进行卷积运算，是一个滤波过程
        - 卷积操作后的图像称为特征图feature-map(叫特征映射图)
    - 填充（0填充）：
        - 在卷积滑动的过程中，图像的边缘会被裁减掉，将5*5的矩阵转换成3*3的矩阵，这导致将会失去一些信息
        - 如果要使得输入尺寸与输入尺寸保持一致，需要用额外的假像素（通常为0）填充边缘
        - 这样在滑动时的卷积核可以允许原始边缘像素位于卷积核的中心，同时延伸到边缘之外的假像素，从而产生输入5*5相同大小的输出
    - 多通道卷积
        - 每个卷积核都会将图像生成为另一幅特征映射图，即一个卷积核提取一种特征
            - 例如竖直方向和水平方向的卷积核提取的特征，分别突出竖直方向和水平方向的特征
        - 为了使得特征提取更充分，可以添加多个卷积核，以提取不同的特征，这就是多通道卷积
            - 每个通道使用一个卷积核进行卷积操作
            - 然后将这些特征图像相同位置上的值相加，生成一张综合的特征图
            - 最后进行加偏置：作用是对每个特征映射图加一个偏置项，以便产生最终的输出特征图

# 降采样层（池化层）：
    - 降采样层通过减小矩阵的长和宽，从而达到减少参数、同时保留有用信息的目标
        - 降采样：即降低特定信号的采样频率的操作
    - 池化是降采样经常使用的技术（也可以通过其他方式实现降采样的目的）
        - 计算图像上一个区域上的某个特定特征的平均值或最大值，这种聚合操作就叫池化
        - 卷积层的作用是探测上一层特征的局部连接，而池化的作用是，在语义上把相似的特征合并起来，从而达到降维的目的
    - 池化后的概要统计特征不仅具有低得多的维度（相比使用所有提取得到的特征），同时还会改善结果（不容易产生过拟合）
    - 常用的池化方法：
        - 均值池化：对池化区域内的像素点取均值，这种方法得到的特征数据对背景信息更敏感
        - 最大池化：对池化区域内的像素点取最大值，这种方法得到的特征数据对纹理特征信息更加敏感
    - CNN网络，隐层与隐层之间的空间分辨率逐层递减，因此，为了检测更多的特征信息、形成更多不同的通道特征组合，从而形成更复杂的特征输出，需要逐渐增加每层所含的平面数（也就是特征映射图的数量）

# 步长
    - 步长是卷积操作的重要概念，它表示卷积核在图片上移动的格数
        - 通过步长的变换，可以得到不同尺寸的卷积输出结果
            - 卷积后图片的尺寸：如步长stride=S，原始图片尺寸为[N1,N1]，卷积核大小为[N2,N2]，则卷积之后的图像大小为：
                - [(N1-N2)/S+1, (N1-N2)/S+1]
            - 例如：5*5的输入，如果步长stride=1,则得到3*3的输出矩阵；如果步长stride=2，则得到2*2的输出矩阵
        - 步长如果大于1，可以达到降维的目的，所以步长大于1的卷积操作也是降维（降采样）的一种方法

# 卷积过程概述
    - 过程概述
        - 输入图像通过若干个“卷积—>降采样”之后，连接成一个向量输入到传统分类器当中，最终得到输出
    - 正则表达式
        - 输入层—>(卷积层+ —>池化层？)+—>全连接层+
            - 卷积层+ : 表示一层或多层卷积层，多数的CNN中使用3层卷积层
            - 池化层？: 表示一层池化层，或者是没有池化层。
                - 一些研究表明，直接通过调整卷积层的步长达到的降维效果比池化层更好
                - 所以一些CNN中并没有使用池化层
            - 全连接层+： 表示一层或多层全连接层
                - 一般经过若干卷积+池化之后，会经过1-2个全连接层，最终得到输出


